# -*- coding: utf-8 -*-
"""cat_or_dog_class_CNNs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fDwQFEq3_nb9F2B4kRnaOPfjV6t5SdGL
"""

# Step 1: Install Kaggle CLI
!pip install -q kaggle

# Step 2: Upload kaggle.json (you'll be prompted to upload the file)
from google.colab import files
files.upload()  # upload kaggle.json here

# Step 3: Move kaggle.json to the correct location
!mkdir -p ~/.kaggle
!mv kaggle_user.json ~/.kaggle/kaggle.json
!chmod 600 ~/.kaggle/kaggle.json

# Step 4: Download the dataset
!kaggle datasets download -d sunilthite/cat-or-dog-image-classification

# Step 5: Unzip the downloaded file
!unzip -q cat-or-dog-image-classification.zip -d ./cat_dog_data

import os
import numpy as np
import tensorflow as tf
import cv2
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout , BatchNormalization , AveragePooling2D ,Dropout
from tensorflow.keras.applications import VGG16 ,ResNet50 , DenseNet121
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import classification_report
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.vgg16 import preprocess_input
from sklearn.metrics import accuracy_score
from tensorflow.keras import models,layers

# Function to load images and labels from a directory
def load_images_from_directory(directory, img_size=(224, 224,3)):
    images = []
    labels = []
    class_names = sorted(os.listdir(directory))  # Get class names
    for class_name in class_names:
        class_path = os.path.join(directory, class_name)
        if not os.path.isdir(class_path):  # Ensure it's a directory
            continue
        label = class_names.index(class_name)
        for i, img_name in enumerate(os.listdir(class_path)):
            if i == 2000:
              break
            img_path = os.path.join(class_path, img_name)

            img = tf.keras.preprocessing.image.load_img(img_path, target_size=img_size)
            # img_array = tf.keras.preprocessing.image.img_to_array(img)  # Convert to array
            images.append(img)
            labels.append(label)

    return np.array(images), np.array(labels), class_names

# Set dataset path
train_path = '/content/cat_dog_data/Train'

# Load images and labels
x, y, class_names = load_images_from_directory(train_path, img_size=(224, 224, 3))

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, shuffle=True)

X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, shuffle=True)

X_train = X_train/255.0
X_test = X_test/255.0
X_val = X_val/255.0

IMG_WIDTH = 224
IMG_HEIGHT = 224
NUM_CLASSES = len(class_names)

# Create a normal CNN model from scratch
model = Sequential()

# First Convolutional Block
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)))
model.add(MaxPooling2D((2, 2)))

# Second Convolutional Block
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))

# Third Convolutional Block
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D((2, 2)))

# Flatten the output to feed into dense layers
model.add(Flatten())

# Dense layers for classification
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid')) # Output layer with sigmoid for binary classification

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

# Print the model summary
model.summary()

history = model.fit(X_train, y_train,
                    epochs=10,
                    batch_size=64,
                    validation_data=(X_val, y_val))

pred=model.predict(X_test)
# Convert continuous predictions to binary predictions using a threshold (e.g., 0.5)
pred_binary = (pred > 0.5).astype(int)
acc= accuracy_score(y_test,pred_binary)
print(acc)

# LeNet
model2 = Sequential()

# First Convolutional Block
model2.add(Conv2D(6, (5, 5), activation='tanh', input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)))
model2.add(AveragePooling2D((2, 2), strides=2))

# Second Convolutional Block
model2.add(Conv2D(16, (5, 5), activation='tanh'))
model2.add(AveragePooling2D((2, 2), strides=2))

# Flatten the output to feed into dense layers
model2.add(Flatten())

# Dense layers for classification
model2.add(Dense(120, activation='tanh'))
model2.add(Dense(84, activation='tanh'))
model2.add(Dense(1, activation='sigmoid')) # Output layer with sigmoid for binary classification

# Compile the model
model2.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

# Print the model summary
model2.summary()

history = model2.fit(X_train, y_train,
                    epochs=10,
                    batch_size=64,
                    validation_data=(X_val, y_val))

pred2=model2.predict(X_test)
# Convert continuous predictions to binary predictions using a threshold (e.g., 0.5)
pred2_binary = (pred2 > 0.5).astype(int)
acc2= accuracy_score(y_test,pred2_binary)
print(acc2)

# AlexNet
model3 = Sequential()

# First Convolutional Block
model3.add(Conv2D(96, (11, 11),strides=4, activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)))
model3.add(MaxPooling2D((3, 3), strides=2))

# Second Convolutional Block
model3.add(Conv2D(256, (5, 5),padding='same', activation='relu'))
model3.add(MaxPooling2D((3, 3), strides=2))

model3.add(Conv2D(384, (3, 3),padding='same', activation='relu'))
model3.add(Conv2D(384, (3, 3),padding='same', activation='relu'))
model3.add(Conv2D(256, (3, 3),padding='same', activation='relu'))
model3.add(MaxPooling2D((3, 3), strides=2))
# Flatten the output to feed into dense layers
model3.add(Flatten())

# Dense layers for classification
model3.add(Dense(4096, activation='relu'))
model3.add(Dropout(0.5))
model3.add(Dense(4096, activation='relu'))
model3.add(Dropout(0.5))
model3.add(Dense(1, activation='sigmoid')) # Output layer with sigmoid for binary classification

# Compile the model
model3.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

# Print the model summary
model3.summary()

history = model3.fit(X_train, y_train,
                    epochs=10,
                    batch_size=64,
                    validation_data=(X_val, y_val))

pred3=model3.predict(X_test)
# Convert continuous predictions to binary predictions using a threshold (e.g., 0.5)
pred3_binary = (pred3 > 0.5).astype(int)
acc3= accuracy_score(y_test,pred3_binary)
print(acc3)

# VGG16
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))
model4 = models.Sequential([
    base_model,
    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])
base_model.trainable = False
model4.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

# Print the model summary
model4.summary()

history = model4.fit(X_train, y_train,
                    epochs=10,
                    batch_size=64,
                    validation_data=(X_val, y_val))

pred4=model4.predict(X_test)
# Convert continuous predictions to binary predictions using a threshold (e.g., 0.5)
pred4_binary = (pred4 > 0.5).astype(int)
acc4= accuracy_score(y_test,pred4_binary)
print(acc4)

# ResNet
base_model_res = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))
model5 = models.Sequential([
    base_model_res,
    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])
base_model_res.trainable = False
model5.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

# Print the model summary
model5.summary()

history = model5.fit(X_train, y_train,
                    epochs=10,
                    batch_size=64,
                    validation_data=(X_val, y_val))

pred5=model5.predict(X_test)
# Convert continuous predictions to binary predictions using a threshold (e.g., 0.5)
pred5_binary = (pred5 > 0.5).astype(int)
acc5= accuracy_score(y_test,pred5_binary)
print(acc5)

# DenseNet
base_model_dense = DenseNet121(weights='imagenet', include_top=False, input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))
model6 = models.Sequential([
    base_model_dense,
    layers.Flatten(),
    layers.Dense(1024, activation='relu'),
    layers.Dropout(0.2),
    layers.Dense(1, activation='sigmoid')
])
base_model_dense.trainable = False
model6.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

# Print the model summary
model6.summary()

history = model6.fit(X_train, y_train,
                    epochs=10,
                    batch_size=64,
                    validation_data=(X_val, y_val))

pred6=model6.predict(X_test)
# Convert continuous predictions to binary predictions using a threshold (e.g., 0.5)
pred6_binary = (pred6 > 0.5).astype(int)
acc6= accuracy_score(y_test,pred6_binary)
print(acc6)